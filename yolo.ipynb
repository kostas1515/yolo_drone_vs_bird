{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "model.load_weights(\"yolov3.weights\")\n",
    "inp = get_test_input()\n",
    "blocks = parse_cfg(\"cfg/yolov3.cfg\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(inp, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 85])\n",
      "torch.Size([1, 4, 85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n"
     ]
    }
   ],
   "source": [
    "array=np.zeros([80])\n",
    "ar2=np.array([122,25,91,46,0.2])\n",
    "ar3=np.array([12,245,16,60,0.1])\n",
    "ar4=np.array([150,45,7,98,0.8])\n",
    "ar5=np.array([22,23,70,403,0.1])\n",
    "\n",
    "\n",
    "ar2=np.concatenate((ar2,array),axis=0)\n",
    "ar3=np.concatenate((ar3,array),axis=0)\n",
    "ar4=np.concatenate((ar4,array),axis=0)\n",
    "ar5=np.concatenate((ar5,array),axis=0)\n",
    "\n",
    "targets=torch.tensor([[ar2,ar3,ar4,ar5]])\n",
    "print(targets.shape)\n",
    "\n",
    "print(targets.shape)\n",
    "for obj in targets[0]:\n",
    "    print(obj.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=3\n",
    "batch=0\n",
    "obj=0\n",
    "target=torch.stack([targets[batch,obj,0:4] for a in range(anchors)])\n",
    "target=target.type(torch.float)\n",
    "target=util.get_abs_coord(target)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "    filename = str(cnt) + '.jpg'\n",
    "    row = []\n",
    "    parsedXML = ET.parse(file)\n",
    "    for node in parsedXML.getroot().iter('object'):\n",
    "        blood_cells = node.find('name').text\n",
    "        xmin = int(node.find('bndbox/xmin').text)\n",
    "        xmax = int(node.find('bndbox/xmax').text)\n",
    "        ymin = int(node.find('bndbox/ymin').text)\n",
    "        ymax = int(node.find('bndbox/ymax').text)\n",
    "        row = [prev_filename, filename, blood_cells, xmin, xmax,ymin, ymax]\n",
    "        df.append(row)\n",
    "    cnt += 1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type','xmin', 'xmax', 'ymin', 'ymax'])\n",
    "\n",
    "data[['filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0,2:]\n",
    "target[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "inp = get_test_input()\n",
    "\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "loss=util.yolo_loss(pred,targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    row=[]\n",
    "    parsedXML = ET.parse(file)\n",
    "    root= parsedXML.getroot()\n",
    "    if (cnt!=1):\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "    else:\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mpg'\n",
    "    for child in root[1][0]:\n",
    "        if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "            for obj in child[0]:\n",
    "                filename=file.split('/')[-1].split('.')[0]\n",
    "                obj_id=child.attrib['id']\n",
    "                framespan=obj.attrib['framespan']\n",
    "                x=int(obj.attrib['x'])\n",
    "                y=int(obj.attrib['y'])\n",
    "                width=int(obj.attrib['width'])\n",
    "                height=int(obj.attrib['height'])\n",
    "                row = [filename, obj_id, framespan, x, y,width, height]\n",
    "                df.append(row)\n",
    "    cnt=cnt+1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['filename', 'obj_id','framespan','x', 'y', 'width', 'height'])\n",
    "data.to_csv('annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import os, sys, random\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# from shutil import copyfile\n",
    "\n",
    "# annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "# cnt = 0\n",
    "# for file in annotations:\n",
    "#     row=[]\n",
    "#     parsedXML = ET.parse(file)\n",
    "#     root= parsedXML.getroot()\n",
    "#     file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "#     cap = cv2.VideoCapture('WOSDETC19/'+file)\n",
    "    \n",
    "#     file_jpg=file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "#     success = True\n",
    "#     while success:\n",
    "#         for child in root[1][0]:\n",
    "#             if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "#                 for obj in child[0]:\n",
    "#                     framespan=obj.attrib['framespan']\n",
    "#                     count = int(framespan.split(':')[0])\n",
    "#                     cap.set(cv2.CAP_PROP_POS_FRAMES, count-1)\n",
    "#                     success, frame = cap.read()\n",
    "#                     cv2.imwrite(\"images/\"+file_jpg+\"_img%d.jpg\" % count, frame)     # save frame as JPEG file      \n",
    "#         success=False\n",
    "#     cnt=cnt+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konsa15/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(254.4145, grad_fn=<AddBackward0>)\n",
      "tensor(44.8857, grad_fn=<AddBackward0>)\n",
      "tensor(29.3417, grad_fn=<AddBackward0>)\n",
      "tensor(29.0508, grad_fn=<AddBackward0>)\n",
      "tensor(32.1104, grad_fn=<AddBackward0>)\n",
      "tensor(32.6144, grad_fn=<AddBackward0>)\n",
      "tensor(32.1921, grad_fn=<AddBackward0>)\n",
      "tensor(31.1048, grad_fn=<AddBackward0>)\n",
      "tensor(30.1128, grad_fn=<AddBackward0>)\n",
      "tensor(28.8102, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8ca1b11cc776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "batch=1\n",
    "k=0\n",
    "cost=0\n",
    "for index, row in df.iterrows():\n",
    "#     imgpath='../images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "#     inp = get_test_input(imgpath)\n",
    "#     targets=torch.tensor([[[row['x']*(416/1980),row['y']*(416/1080),row['width']*(416/1980),row['height']*(416/1080),1,1]]])\n",
    "#     pred = model(inp, torch.cuda.is_available())\n",
    "#     loss=util.yolo_loss(pred,targets)\n",
    "#     print(loss)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "    index=1\n",
    "    imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "    inp = get_test_input(imgpath)\n",
    "    targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "    pred = model(inp, torch.cuda.is_available())\n",
    "    loss=util.yolo_loss(pred,targets)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#     cost=cost+loss\n",
    "#     if(k==batch):\n",
    "#         print(cost)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "#         cost=0\n",
    "#         k=0\n",
    "#     k=k+1\n",
    "    \n",
    "\n",
    "   \n",
    "index=10\n",
    "imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "inp = get_test_input(imgpath)\n",
    "targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "print(pred)\n",
    "loss=util.yolo_loss(pred,targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=torch.tensor([123.5394, 284.6519,   5.2525,   6.9333,   1.0000,   1.0000])\n",
    "box=torch.tensor([[9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02],\n",
    "        [9.6394e+01, 2.5649e+02, 1.3267e+00, 3.3532e-01, 2.0614e-03, 8.3126e-03],\n",
    "        [9.6071e+01, 2.5609e+02, 1.1885e+00, 4.8042e-01, 2.5095e-03, 2.6043e-03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 72.4265, 236.5345, 117.5735, 292.7255],\n",
      "        [ 94.7306, 255.3223,  96.0574, 255.6577],\n",
      "        [ 94.4767, 254.8498,  95.6653, 255.3302]])\n"
     ]
    }
   ],
   "source": [
    "absolute_box=util.get_abs_coord(box[:,0:4])\n",
    "mask=get_mask(obj[0:2],13,416,3)\n",
    "\n",
    "print(absolute_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target_box=torch.stack([obj[0:4] for a in range(3)])\n",
    "target_box=target_box.type(torch.float)\n",
    "target_box=get_abs_coord(target_box)\n",
    "\n",
    "iou=util.bbox_iou(target_box,absolute_box)\n",
    "\n",
    "iou_mask=iou.max() == iou\n",
    "box=box[iou_mask,:]\n",
    "iou_value=iou.max()\n",
    "print(iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02])\n"
     ]
    }
   ],
   "source": [
    "print(box[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(0.0240, grad_fn=<AddBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
