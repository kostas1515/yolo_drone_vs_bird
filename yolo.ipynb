{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-e4d3378a87ac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e4d3378a87ac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch.tensor([[][][]]).shape\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torch.tensor().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "inp_dim=model.inp_dim\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    imgpath='../images/images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "    inp = get_test_input(imgpath)\n",
    "    target=torch.tensor([[[row['x']/(1920),row['y']/(1080),row['width']/(1920),row['height']/(1080),1,1]]])\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.8333e-01, 1.2139e+02, 1.5583e+01, 2.1659e+01, 5.4400e+02,\n",
      "          5.4400e+02]]])\n"
     ]
    }
   ],
   "source": [
    "inp_dim=model.inp_dim\n",
    "print(target*inp_dim)\n",
    "target= (target.squeeze(-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu but got device cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-023f8b5ee1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mraw_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpw_ph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcx_cy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# raw_pred=raw_pred.to(device='cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/notebooks/drone_vs_bird/yolo_drone_vs_bird/darknet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, CUDA)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m#Transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manchs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxyoffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m#if no collector has been intialised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/notebooks/drone_vs_bird/yolo_drone_vs_bird/util.py\u001b[0m in \u001b[0;36mpredict_transform\u001b[0;34m(prediction, inp_dim, anchors, num_classes, CUDA)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mx_y_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx_y_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cpu but got device cuda:0"
     ]
    }
   ],
   "source": [
    "target=util.xyxy_to_xywh(target) # target in normal scale\n",
    "\n",
    "inp_dim=model.inp_dim\n",
    "\n",
    "raw_pred,pw_ph,cx_cy,stride = model(inp, True)\n",
    "# raw_pred=raw_pred.to(device='cuda')\n",
    "\n",
    "true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "\n",
    "\n",
    "\n",
    "true_pred=true_pred.squeeze(-3)\n",
    "\n",
    "iou_mask,noobj_mask=util.get_responsible_masks(true_pred,target*inp_dim)\n",
    "\n",
    "\n",
    "raw_pred=raw_pred.squeeze(-3)\n",
    "pw_ph=pw_ph.squeeze(-3)\n",
    "cx_cy=cx_cy.squeeze(-3)\n",
    "stride=stride.squeeze(-3)\n",
    "\n",
    "noobj_box=raw_pred[:,4].clone()\n",
    "noobj_box=noobj_box[noobj_mask]\n",
    "\n",
    "raw_pred=raw_pred[iou_mask,:]\n",
    "pw_ph=pw_ph[iou_mask,:]\n",
    "cx_cy=cx_cy[iou_mask,:]\n",
    "stride=stride[iou_mask,:]\n",
    "\n",
    "target[0,0:4]=target[0,0:4]*(inp_dim/stride)\n",
    "\n",
    "target=util.transform_groundtruth(target,pw_ph,cx_cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2024fc75dfbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoobj_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(raw_pred.shape)\n",
    "print(noobj_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_obj_conf_loss=0\n",
    "for no_obj in noobj_box: \n",
    "    no_obj_conf_loss =no_obj_conf_loss + (0-no_obj)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4346.0645, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(no_obj_conf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3.9615, 123.9904,  15.1550,  29.6256,   0.4966,   0.4970]],\n",
      "       grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(true_pred[iou_mask,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "inp = get_test_input('../dog-cycle-car.png')\n",
    "tranf_pred,anchs,grid = model(inp,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.5092e-06, 1.9475e+01, 1.4379e+02, 9.2864e+01, 2.5936e-06,\n",
      "          1.5060e-02],\n",
      "         [9.2512e-02, 1.9531e-01, 5.9632e-01, 8.7011e-01, 5.8082e-04,\n",
      "          9.6061e-04],\n",
      "         [9.5038e-02, 2.2195e-02, 6.2958e-01, 1.3883e-01, 7.0117e-04,\n",
      "          4.9626e-04],\n",
      "         ...,\n",
      "         [5.4007e+02, 5.4011e+02, 1.0284e+01, 1.3622e+01, 4.9354e-01,\n",
      "          4.8176e-01],\n",
      "         [5.3996e+02, 5.3999e+02, 1.5509e+01, 2.9669e+01, 4.9595e-01,\n",
      "          4.9371e-01],\n",
      "         [5.3996e+02, 5.3999e+02, 3.2917e+01, 2.3590e+01, 5.0755e-01,\n",
      "          5.0578e-01]]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(tranf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-28f27847d67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../annotations.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "df.describe()\n",
    "points=np.array([df['width'],df['height']]).T\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(points)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191102976"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(330000)\n",
    "576*576*576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=torch.tensor([[40.0,40.0,1.0,5.9]])\n",
    "abs_target=util.get_abs_target_coord(target)\n",
    "abs_pred_box=util.get_abs_pred_coord(pred[0])\n",
    "\n",
    "box=pred[0]\n",
    "\n",
    "\n",
    "iou=util.bbox_iou(abs_target,abs_pred_box)\n",
    "iou_mask=iou.max() == iou\n",
    "\n",
    "ignore_mask=0.5<iou\n",
    "\n",
    "final_mask=ignore_mask* iou.max() != iou\n",
    "noobj_box=box[final_mask,:]\n",
    "\n",
    "\n",
    "\n",
    "abs_pred_box=pred[0,iou_mask,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17*17*3+34*34*3+68*68*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18207 is out of bounds for dimension 0 with size 18207",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a0b4a9ab2b6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18207\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 18207 is out of bounds for dimension 0 with size 18207"
     ]
    }
   ],
   "source": [
    "print(iou_mask[18207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5370]])\n"
     ]
    }
   ],
   "source": [
    "a= ((iou_mask == True).nonzero())\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 85])\n",
      "torch.Size([1, 4, 85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n"
     ]
    }
   ],
   "source": [
    "array=np.zeros([80])\n",
    "ar2=np.array([122,25,91,46,0.2])\n",
    "ar3=np.array([12,245,16,60,0.1])\n",
    "ar4=np.array([150,45,7,98,0.8])\n",
    "ar5=np.array([22,23,70,403,0.1])\n",
    "\n",
    "\n",
    "ar2=np.concatenate((ar2,array),axis=0)\n",
    "ar3=np.concatenate((ar3,array),axis=0)\n",
    "ar4=np.concatenate((ar4,array),axis=0)\n",
    "ar5=np.concatenate((ar5,array),axis=0)\n",
    "\n",
    "targets=torch.tensor([[ar2,ar3,ar4,ar5]])\n",
    "print(targets.shape)\n",
    "\n",
    "print(targets.shape)\n",
    "for obj in targets[0]:\n",
    "    print(obj.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=3\n",
    "batch=0\n",
    "obj=0\n",
    "target=torch.stack([targets[batch,obj,0:4] for a in range(anchors)])\n",
    "target=target.type(torch.float)\n",
    "target=util.get_abs_coord(target)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, cell_type, xmin, xmax, ymin, ymax]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "    filename = str(cnt) + '.jpg'\n",
    "    row = []\n",
    "    parsedXML = ET.parse(file)\n",
    "    for node in parsedXML.getroot().iter('object'):\n",
    "        blood_cells = node.find('name').text\n",
    "        xmin = int(node.find('bndbox/xmin').text)\n",
    "        xmax = int(node.find('bndbox/xmax').text)\n",
    "        ymin = int(node.find('bndbox/ymin').text)\n",
    "        ymax = int(node.find('bndbox/ymax').text)\n",
    "        row = [prev_filename, filename, blood_cells, xmin, xmax,ymin, ymax]\n",
    "        df.append(row)\n",
    "    cnt += 1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type','xmin', 'xmax', 'ymin', 'ymax'])\n",
    "\n",
    "data[['filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0,2:]\n",
    "target[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_test_input() missing 1 required positional argument: 'imgpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4622565eeb03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_test_input() missing 1 required positional argument: 'imgpath'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "inp = get_test_input()\n",
    "\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "loss=util.yolo_loss(pred,targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    row=[]\n",
    "    parsedXML = ET.parse(file)\n",
    "    root= parsedXML.getroot()\n",
    "    if (cnt!=1):\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "    else:\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mpg'\n",
    "    for child in root[1][0]:\n",
    "        if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "            for obj in child[0]:\n",
    "                filename=file.split('/')[-1].split('.')[0]\n",
    "                obj_id=child.attrib['id']\n",
    "                framespan=obj.attrib['framespan']\n",
    "                x=int(obj.attrib['x'])\n",
    "                y=int(obj.attrib['y'])\n",
    "                width=int(obj.attrib['width'])\n",
    "                height=int(obj.attrib['height'])\n",
    "                row = [filename, obj_id, framespan, x, y,width, height]\n",
    "                df.append(row)\n",
    "    cnt=cnt+1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['filename', 'obj_id','framespan','x', 'y', 'width', 'height'])\n",
    "data.to_csv('annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import os, sys, random\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# from shutil import copyfile\n",
    "\n",
    "# annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "# cnt = 0\n",
    "# for file in annotations:\n",
    "#     row=[]\n",
    "#     parsedXML = ET.parse(file)\n",
    "#     root= parsedXML.getroot()\n",
    "#     file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "#     cap = cv2.VideoCapture('WOSDETC19/'+file)\n",
    "    \n",
    "#     file_jpg=file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "#     success = True\n",
    "#     while success:\n",
    "#         for child in root[1][0]:\n",
    "#             if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "#                 for obj in child[0]:\n",
    "#                     framespan=obj.attrib['framespan']\n",
    "#                     count = int(framespan.split(':')[0])\n",
    "#                     cap.set(cv2.CAP_PROP_POS_FRAMES, count-1)\n",
    "#                     success, frame = cap.read()\n",
    "#                     cv2.imwrite(\"images/\"+file_jpg+\"_img%d.jpg\" % count, frame)     # save frame as JPEG file      \n",
    "#         success=False\n",
    "#     cnt=cnt+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>obj_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.179736</td>\n",
       "      <td>0.386403</td>\n",
       "      <td>-0.297138</td>\n",
       "      <td>-0.324744</td>\n",
       "      <td>-0.309528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj_id</th>\n",
       "      <td>-0.179736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065915</td>\n",
       "      <td>0.102089</td>\n",
       "      <td>-0.050285</td>\n",
       "      <td>-0.007669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.386403</td>\n",
       "      <td>-0.065915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.375353</td>\n",
       "      <td>0.141238</td>\n",
       "      <td>0.141141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.297138</td>\n",
       "      <td>0.102089</td>\n",
       "      <td>-0.375353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040109</td>\n",
       "      <td>-0.053514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>-0.324744</td>\n",
       "      <td>-0.050285</td>\n",
       "      <td>0.141238</td>\n",
       "      <td>-0.040109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>-0.309528</td>\n",
       "      <td>-0.007669</td>\n",
       "      <td>0.141141</td>\n",
       "      <td>-0.053514</td>\n",
       "      <td>0.978448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0    obj_id         x         y     width    height\n",
       "Unnamed: 0    1.000000 -0.179736  0.386403 -0.297138 -0.324744 -0.309528\n",
       "obj_id       -0.179736  1.000000 -0.065915  0.102089 -0.050285 -0.007669\n",
       "x             0.386403 -0.065915  1.000000 -0.375353  0.141238  0.141141\n",
       "y            -0.297138  0.102089 -0.375353  1.000000 -0.040109 -0.053514\n",
       "width        -0.324744 -0.050285  0.141238 -0.040109  1.000000  0.978448\n",
       "height       -0.309528 -0.007669  0.141141 -0.053514  0.978448  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "df.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konsa15/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(518.8747, grad_fn=<AddBackward0>)\n",
      "tensor(334.6520, grad_fn=<AddBackward0>)\n",
      "tensor(296.8161, grad_fn=<AddBackward0>)\n",
      "tensor(288.6065, grad_fn=<AddBackward0>)\n",
      "tensor(289.0010, grad_fn=<AddBackward0>)\n",
      "tensor(290.6425, grad_fn=<AddBackward0>)\n",
      "tensor(292.0215, grad_fn=<AddBackward0>)\n",
      "tensor(292.9909, grad_fn=<AddBackward0>)\n",
      "tensor(293.6782, grad_fn=<AddBackward0>)\n",
      "tensor(294.1308, grad_fn=<AddBackward0>)\n",
      "tensor(294.4370, grad_fn=<AddBackward0>)\n",
      "tensor(294.6374, grad_fn=<AddBackward0>)\n",
      "tensor(294.7421, grad_fn=<AddBackward0>)\n",
      "tensor(294.7888, grad_fn=<AddBackward0>)\n",
      "tensor(294.7904, grad_fn=<AddBackward0>)\n",
      "tensor(294.7456, grad_fn=<AddBackward0>)\n",
      "tensor(294.6743, grad_fn=<AddBackward0>)\n",
      "tensor(294.5497, grad_fn=<AddBackward0>)\n",
      "tensor(294.3137, grad_fn=<AddBackward0>)\n",
      "tensor(293.8732, grad_fn=<AddBackward0>)\n",
      "tensor(293.1480, grad_fn=<AddBackward0>)\n",
      "tensor(291.8376, grad_fn=<AddBackward0>)\n",
      "tensor(289.2444, grad_fn=<AddBackward0>)\n",
      "tensor(283.1244, grad_fn=<AddBackward0>)\n",
      "tensor(275.8295, grad_fn=<AddBackward0>)\n",
      "tensor(283.5142, grad_fn=<AddBackward0>)\n",
      "tensor(149.7327, grad_fn=<AddBackward0>)\n",
      "tensor(329.7397, grad_fn=<AddBackward0>)\n",
      "tensor(247.6086, grad_fn=<AddBackward0>)\n",
      "tensor(252.1393, grad_fn=<AddBackward0>)\n",
      "tensor(252.3655, grad_fn=<AddBackward0>)\n",
      "tensor(249.2338, grad_fn=<AddBackward0>)\n",
      "tensor(226.1428, grad_fn=<AddBackward0>)\n",
      "tensor(275.6034, grad_fn=<AddBackward0>)\n",
      "tensor(280.9270, grad_fn=<AddBackward0>)\n",
      "tensor(291.2644, grad_fn=<AddBackward0>)\n",
      "tensor(284.9958, grad_fn=<AddBackward0>)\n",
      "tensor(290.3095, grad_fn=<AddBackward0>)\n",
      "tensor(292.4133, grad_fn=<AddBackward0>)\n",
      "tensor(293.3036, grad_fn=<AddBackward0>)\n",
      "tensor(293.6723, grad_fn=<AddBackward0>)\n",
      "tensor(293.8141, grad_fn=<AddBackward0>)\n",
      "tensor(293.7965, grad_fn=<AddBackward0>)\n",
      "tensor(293.6169, grad_fn=<AddBackward0>)\n",
      "tensor(293.2276, grad_fn=<AddBackward0>)\n",
      "tensor(292.5967, grad_fn=<AddBackward0>)\n",
      "tensor(291.6919, grad_fn=<AddBackward0>)\n",
      "tensor(290.2274, grad_fn=<AddBackward0>)\n",
      "tensor(287.7288, grad_fn=<AddBackward0>)\n",
      "tensor(283.6049, grad_fn=<AddBackward0>)\n",
      "tensor(278.0563, grad_fn=<AddBackward0>)\n",
      "tensor(280.6510, grad_fn=<AddBackward0>)\n",
      "tensor(287.2223, grad_fn=<AddBackward0>)\n",
      "tensor(276.5089, grad_fn=<AddBackward0>)\n",
      "tensor(278.5320, grad_fn=<AddBackward0>)\n",
      "tensor(281.7282, grad_fn=<AddBackward0>)\n",
      "tensor(283.5850, grad_fn=<AddBackward0>)\n",
      "tensor(284.3137, grad_fn=<AddBackward0>)\n",
      "tensor(284.3471, grad_fn=<AddBackward0>)\n",
      "tensor(283.9852, grad_fn=<AddBackward0>)\n",
      "tensor(283.4743, grad_fn=<AddBackward0>)\n",
      "tensor(283.0549, grad_fn=<AddBackward0>)\n",
      "tensor(282.9599, grad_fn=<AddBackward0>)\n",
      "tensor(282.8905, grad_fn=<AddBackward0>)\n",
      "tensor(281.9873, grad_fn=<AddBackward0>)\n",
      "tensor(280.0950, grad_fn=<AddBackward0>)\n",
      "tensor(277.9273, grad_fn=<AddBackward0>)\n",
      "tensor(276.4041, grad_fn=<AddBackward0>)\n",
      "tensor(275.8270, grad_fn=<AddBackward0>)\n",
      "tensor(276.0414, grad_fn=<AddBackward0>)\n",
      "tensor(276.6113, grad_fn=<AddBackward0>)\n",
      "tensor(277.1285, grad_fn=<AddBackward0>)\n",
      "tensor(277.5946, grad_fn=<AddBackward0>)\n",
      "tensor(278.1458, grad_fn=<AddBackward0>)\n",
      "tensor(278.6989, grad_fn=<AddBackward0>)\n",
      "tensor(279.1109, grad_fn=<AddBackward0>)\n",
      "tensor(279.2447, grad_fn=<AddBackward0>)\n",
      "tensor(279.1997, grad_fn=<AddBackward0>)\n",
      "tensor(279.2378, grad_fn=<AddBackward0>)\n",
      "tensor(279.3773, grad_fn=<AddBackward0>)\n",
      "tensor(279.2800, grad_fn=<AddBackward0>)\n",
      "tensor(278.9734, grad_fn=<AddBackward0>)\n",
      "tensor(278.7079, grad_fn=<AddBackward0>)\n",
      "tensor(67.1986, grad_fn=<AddBackward0>)\n",
      "tensor(238.3528, grad_fn=<AddBackward0>)\n",
      "tensor(222.5354, grad_fn=<AddBackward0>)\n",
      "tensor(13.8361, grad_fn=<AddBackward0>)\n",
      "tensor(124.3917, grad_fn=<AddBackward0>)\n",
      "tensor(38.3191, grad_fn=<AddBackward0>)\n",
      "tensor(35.7672, grad_fn=<AddBackward0>)\n",
      "tensor(321.5696, grad_fn=<AddBackward0>)\n",
      "tensor(282.1562, grad_fn=<AddBackward0>)\n",
      "tensor(291.9547, grad_fn=<AddBackward0>)\n",
      "tensor(295.1422, grad_fn=<AddBackward0>)\n",
      "tensor(295.9092, grad_fn=<AddBackward0>)\n",
      "tensor(296.1133, grad_fn=<AddBackward0>)\n",
      "tensor(296.1783, grad_fn=<AddBackward0>)\n",
      "tensor(296.2067, grad_fn=<AddBackward0>)\n",
      "tensor(296.2185, grad_fn=<AddBackward0>)\n",
      "tensor(296.2229, grad_fn=<AddBackward0>)\n",
      "tensor(296.2249, grad_fn=<AddBackward0>)\n",
      "tensor(296.2244, grad_fn=<AddBackward0>)\n",
      "tensor(296.2209, grad_fn=<AddBackward0>)\n",
      "tensor(296.2140, grad_fn=<AddBackward0>)\n",
      "tensor(296.2030, grad_fn=<AddBackward0>)\n",
      "tensor(296.1895, grad_fn=<AddBackward0>)\n",
      "tensor(296.1746, grad_fn=<AddBackward0>)\n",
      "tensor(296.1578, grad_fn=<AddBackward0>)\n",
      "tensor(296.1392, grad_fn=<AddBackward0>)\n",
      "tensor(296.1147, grad_fn=<AddBackward0>)\n",
      "tensor(296.0828, grad_fn=<AddBackward0>)\n",
      "tensor(296.0436, grad_fn=<AddBackward0>)\n",
      "tensor(295.9961, grad_fn=<AddBackward0>)\n",
      "tensor(295.9387, grad_fn=<AddBackward0>)\n",
      "tensor(295.8748, grad_fn=<AddBackward0>)\n",
      "tensor(295.7996, grad_fn=<AddBackward0>)\n",
      "tensor(295.7159, grad_fn=<AddBackward0>)\n",
      "tensor(295.6308, grad_fn=<AddBackward0>)\n",
      "tensor(295.5485, grad_fn=<AddBackward0>)\n",
      "tensor(295.4778, grad_fn=<AddBackward0>)\n",
      "tensor(295.4245, grad_fn=<AddBackward0>)\n",
      "tensor(295.3893, grad_fn=<AddBackward0>)\n",
      "tensor(295.3696, grad_fn=<AddBackward0>)\n",
      "tensor(295.3579, grad_fn=<AddBackward0>)\n",
      "tensor(295.3505, grad_fn=<AddBackward0>)\n",
      "tensor(295.3459, grad_fn=<AddBackward0>)\n",
      "tensor(295.3429, grad_fn=<AddBackward0>)\n",
      "tensor(295.3411, grad_fn=<AddBackward0>)\n",
      "tensor(295.3399, grad_fn=<AddBackward0>)\n",
      "tensor(295.3392, grad_fn=<AddBackward0>)\n",
      "tensor(295.3388, grad_fn=<AddBackward0>)\n",
      "tensor(295.3385, grad_fn=<AddBackward0>)\n",
      "tensor(295.3384, grad_fn=<AddBackward0>)\n",
      "tensor(295.3383, grad_fn=<AddBackward0>)\n",
      "tensor(295.3382, grad_fn=<AddBackward0>)\n",
      "tensor(295.3382, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3381, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3380, grad_fn=<AddBackward0>)\n",
      "tensor(295.3379, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3e079b5ef396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/notebooks/drone_vs_bird/yolo_drone_vs_bird/darknet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, CUDA)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"convolutional\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"upsample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"route\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "batch=1\n",
    "k=0\n",
    "cost=0\n",
    "for index, row in df.iterrows():\n",
    "#     imgpath='../images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "#     inp = get_test_input(imgpath)\n",
    "#     targets=torch.tensor([[[row['x']*(416/1980),row['y']*(416/1080),row['width']*(416/1980),row['height']*(416/1080),1,1]]])\n",
    "#     pred = model(inp, torch.cuda.is_available())\n",
    "#     loss=util.yolo_loss(pred,targets)\n",
    "#     print(loss)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "    index=1\n",
    "    imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "    inp = get_test_input(imgpath)\n",
    "    targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "    pred = model(inp, torch.cuda.is_available())\n",
    "    loss=util.yolo_loss(pred,targets)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#     cost=cost+loss\n",
    "#     if(k==batch):\n",
    "#         print(cost)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "#         cost=0\n",
    "#         k=0\n",
    "#     k=k+1\n",
    "    \n",
    "\n",
    "   \n",
    "index=10\n",
    "imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "inp = get_test_input(imgpath)\n",
    "targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "print(pred)\n",
    "loss=util.yolo_loss(pred,targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=torch.tensor([123.5394, 284.6519,   5.2525,   6.9333,   1.0000,   1.0000])\n",
    "box=torch.tensor([[9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02],\n",
    "        [9.6394e+01, 2.5649e+02, 1.3267e+00, 3.3532e-01, 2.0614e-03, 8.3126e-03],\n",
    "        [9.6071e+01, 2.5609e+02, 1.1885e+00, 4.8042e-01, 2.5095e-03, 2.6043e-03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 72.4265, 236.5345, 117.5735, 292.7255],\n",
      "        [ 94.7306, 255.3223,  96.0574, 255.6577],\n",
      "        [ 94.4767, 254.8498,  95.6653, 255.3302]])\n"
     ]
    }
   ],
   "source": [
    "absolute_box=util.get_abs_coord(box[:,0:4])\n",
    "mask=get_mask(obj[0:2],13,416,3)\n",
    "\n",
    "print(absolute_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target_box=torch.stack([obj[0:4] for a in range(3)])\n",
    "target_box=target_box.type(torch.float)\n",
    "target_box=get_abs_coord(target_box)\n",
    "\n",
    "iou=util.bbox_iou(target_box,absolute_box)\n",
    "\n",
    "iou_mask=iou.max() == iou\n",
    "box=box[iou_mask,:]\n",
    "iou_value=iou.max()\n",
    "print(iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02])\n"
     ]
    }
   ],
   "source": [
    "print(box[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(0.0240, grad_fn=<AddBackward0>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for x in pbar(range(10)):\n",
    "    x==x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress is 9"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-56d7624e8dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rProgress is %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    sys.stdout.write('\\rProgress is %d' %i)\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konsa15/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress is 0.0% loss is: 281.5664367675781 Time remaining is 0.0 min"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ab0bb603537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rProgress is '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprg_counter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8771\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%'\u001b[0m \u001b[0;34m' loss is: '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' Time remaining is '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "batch=1\n",
    "\n",
    "epochs=20\n",
    "start = timeit.default_timer()\n",
    "\n",
    "lock=0\n",
    "remaining=0\n",
    "estimated=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    print(\"epoch \"+str(e))\n",
    "    for index, row in df.iterrows():\n",
    "        imgpath='../images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "        inp = get_test_input(imgpath)\n",
    "        targets=torch.tensor([[[row['x']*(416/1980),row['y']*(416/1080),row['width']*(416/1980),row['height']*(416/1080),1,1]]])\n",
    "        pred = model(inp, torch.cuda.is_available())\n",
    "        loss=util.yolo_loss(pred,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\rProgress is ' +str(prg_counter/8771*100)+'%' ' loss is: '+ str(loss.item())+' Time remaining is ' +str(estimated/60)+' min')\n",
    "        sys.stdout.flush()\n",
    "        prg_counter=prg_counter+1\n",
    "        if ((prg_counter/8771*100>1)&(lock==0)):\n",
    "            stop = timeit.default_timer()\n",
    "            estimated= (stop-start)*99\n",
    "            dur=stop-start\n",
    "            start=stop\n",
    "            lock=1\n",
    "        if estimated!=0:\n",
    "            stop = timeit.default_timer()\n",
    "            dur=stop-start\n",
    "            start=stop\n",
    "            estimated=estimated-dur\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.437082052230835"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=time.time()\n",
    "for x in range(100000000):\n",
    "    x=x+x\n",
    "time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Using  2 GPUs!\n",
      "0.01647801697254181\n",
      "0.009011506102979183\n",
      "0.03468147665262222\n",
      "0.01256517693400383\n",
      "0.012057092040777206\n",
      "0.009695269167423248\n",
      "0.0059318868443369865\n",
      "0.008672541938722134\n",
      "0.005090699531137943\n",
      "0.01452274713665247\n",
      "0.02868800424039364\n",
      "0.0034340033307671547\n",
      "0.0075789643451571465\n",
      "0.018371228128671646\n",
      "0.009470767341554165\n",
      "0.11426515877246857\n",
      "0.14587651193141937\n",
      "0.1941090226173401\n",
      "0.21469636261463165\n",
      "0.21769261360168457\n",
      "0.2082846760749817\n",
      "0.16980497539043427\n",
      "0.15823329985141754\n",
      "0.15460997819900513\n",
      "0.1609727293252945\n",
      "0.11344296485185623\n"
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../test_annotations.csv')\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './darknet.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluation_df = pd.DataFrame(columns=['pred_x', 'pred_y', 'pred_w','pred_h','pred_conf','pred_class','true_x','true_y','true_w','true_h','true_conf','true_class'])\n",
    "epochs=1\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['obj_id']==0)&(row['filename']+'_'+str(row['obj_id'])+'_img'+row['framespan'].split(':')[0]+'.jpg'!='gopro_001_0_img480.jpg'):\n",
    "            imgpath='../test_images/'+row['filename']+'_'+str(row['obj_id'])+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "            inp = get_test_input(imgpath)\n",
    "            targets=torch.tensor([[[row['x']*(416/1920),row['y']*(416/1080),row['width']*(416/1920),row['height']*(416/1080),1,1]]])\n",
    "            targets=targets.to(device='cuda')\n",
    "            pred = model(inp, torch.cuda.is_available())\n",
    "            pred=pred.to(device='cuda')\n",
    "            pred_mask=pred[0,:,4].max() == pred[0,:,4]\n",
    "            pred_final=pred[:,pred_mask]\n",
    "            pred_final=pred_final[0]\n",
    "            \n",
    "            abs_gt=util.get_abs_target_coord(targets[0])\n",
    "            abs_pred=util.get_abs_pred_coord(pred_final)\n",
    "            if util.bbox_iou(abs_gt, abs_pred).item()>0:\n",
    "                print(util.bbox_iou(abs_gt, abs_pred).item())\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*13\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-044b88d4a380>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-044b88d4a380>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dct={'pred_x':pred_final[0,0,0]*1980/416, 'pred_y':pred_final[0,0,1]*1080/416, 'pred_w':pred_final[0,0,2]*1980/416,'pred_h':pred_final[0,0,3]*1080/416,'pred_conf':pred_final[0,0,4],'pred_class':pred_final[0,0,5],'true_x':row['x'],'true_y':row['y'],'true_w':row['width'],'true_h':row['height]','true_conf':'1','true_class':'1'}\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dct={'pred_x':pred_final[0,0,0]*1980/416, 'pred_y':pred_final[0,0,1]*1080/416, 'pred_w':pred_final[0,0,2]*1980/416,'pred_h':pred_final[0,0,3]*1080/416,'pred_conf':pred_final[0,0,4],'pred_class':pred_final[0,0,5],'true_x':row['x'],'true_y':'as','true_w':'as','true_h':row['height'],'true_conf':'1','true_class':'1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(columns=['pred_x', 'pred_y', 'pred_w','pred_h','pred_conf','pred_class','true_x','true_y','true_w','true_h','true_conf','true_class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
