{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import util\n",
    "\n",
    "\n",
    "a=torch.tensor([[[0.4685, 0.6449, 0.4902, 0.6693]]])\n",
    "b=torch.tensor([[[0.4565, 0.6445, 0.4769, 0.6696]]])\n",
    "\n",
    "c=torch.tensor([10.0])\n",
    "print(torch.sigmoid(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_x1, b1_y1, b1_x2, b1_y2 = a[:,:,0], a[:,:,1], a[:,:,2], a[:,:,3]\n",
    "b2_x1, b2_y1, b2_x2, b2_y2 = b[:,:,0], b[:,:,1], b[:,:,2], b[:,:,3]\n",
    "\n",
    "inter_area = torch.max(inter_rect_x2 - inter_rect_x1 ,torch.zeros(inter_rect_x2.shape))*torch.max(inter_rect_y2 - inter_rect_y1 , torch.zeros(inter_rect_x2.shape))\n",
    "    \n",
    "#Union Area\n",
    "b1_area = (b1_x2 - b1_x1 )*(b1_y2 - b1_y1 )\n",
    "b2_area = (b2_x2 - b2_x1 )*(b2_y2 - b2_y1 )\n",
    "\n",
    "iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "\n",
    "print(inter_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_rect_x1 =  torch.max(b1_x1, b2_x1)\n",
    "inter_rect_y1 =  torch.max(b1_y1, b2_y1)\n",
    "inter_rect_x2 =  torch.min(b1_x2, b2_x2)\n",
    "inter_rect_y2 =  torch.min(b1_y2, b2_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inter_rect_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "inp_dim=model.inp_dim\n",
    "pw_ph=model.pw_ph\n",
    "cx_cy=model.cx_cy\n",
    "stride=model.stride\n",
    "anchors=torch.empty(pw_ph.shape).cuda()\n",
    "offset=torch.empty(cx_cy.shape).cuda()\n",
    "strd=torch.empty(stride.shape).cuda()\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "targets=torch.empty(6)\n",
    "write=0\n",
    "k=0\n",
    "inputs=torch.empty(3,544,544)\n",
    "anchors=torch.empty(1)\n",
    "for index, row in df.iterrows():\n",
    "    imgpath='../images/images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "    inp = get_test_input(imgpath)\n",
    "    target=torch.tensor([[[row['x']/(1920),row['y']/(1080),row['width']/(1920),row['height']/(1080),1,1]]])\n",
    "    if (write==0):\n",
    "        targets=target\n",
    "        inputs=inp\n",
    "        anchors=pw_ph\n",
    "        offset=cx_cy\n",
    "        strd=stride\n",
    "        write=1\n",
    "    else:\n",
    "        targets=torch.cat((targets,target),1)\n",
    "        inputs=torch.cat((inputs,inp),0)\n",
    "        anchors=torch.cat((anchors,pw_ph),0)\n",
    "        offset=torch.cat((offset,cx_cy),0)\n",
    "        strd=torch.cat((strd,stride),0)\n",
    "    if(k==15):\n",
    "        break\n",
    "    k=k+1\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "targets=util.xyxy_to_xywh(targets) # target in normal scale\n",
    "inp_dim=model.inp_dim\n",
    "\n",
    "raw_pred = model(inputs, True)\n",
    "raw_pred=raw_pred.cuda()\n",
    "true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_pred = model(inputs, True)\n",
    "# raw_pred=raw_pred.to(device='cuda')\n",
    "\n",
    "\n",
    "iou_mask,noobj_mask=util.get_responsible_masks(true_pred,targets*inp_dim)\n",
    "\n",
    "print(noobj_mask.shape)\n",
    "# pw_ph=pw_ph.squeeze(-3)\n",
    "# cx_cy=cx_cy.squeeze(-3)\n",
    "# stride=stride.squeeze(-3)\n",
    "\n",
    "noobj_box=raw_pred[:,:,4:5].clone()\n",
    "print(noobj_box.shape)\n",
    "\n",
    "noobj_box=noobj_box[noobj_mask.T,:]\n",
    "raw_pred=raw_pred[iou_mask.T,:]\n",
    "anchors=anchors[iou_mask.T,:]\n",
    "offset=offset[iou_mask.T,:]\n",
    "strd=strd[iou_mask.T,:]\n",
    "print(noobj_box.shape)\n",
    "# target[0,0:4]=target[0,0:4]*(inp_dim/stride)\n",
    "\n",
    "# target=util.transform_groundtruth(target,pw_ph,cx_cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0=targets.squeeze(-2)\n",
    "\n",
    "test=test0*(inp_dim/strd)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(targets.shape)\n",
    "targets=util.transform_groundtruth(test,anchors,offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(targets.shape)\n",
    "print(raw_pred.shape)\n",
    "print(noobj_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_loss = (1-raw_pred[:,4])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confidence_loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_pred[iou_mask,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "inp = get_test_input('../dog-cycle-car.png')\n",
    "tranf_pred,anchs,grid = model(inp,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tranf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "df.describe()\n",
    "points=np.array([df['width'],df['height']]).T\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(points)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(330000)\n",
    "576*576*576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=torch.tensor([[40.0,40.0,1.0,5.9]])\n",
    "abs_target=util.get_abs_target_coord(target)\n",
    "abs_pred_box=util.get_abs_pred_coord(pred[0])\n",
    "\n",
    "box=pred[0]\n",
    "\n",
    "\n",
    "iou=util.bbox_iou(abs_target,abs_pred_box)\n",
    "iou_mask=iou.max() == iou\n",
    "\n",
    "ignore_mask=0.5<iou\n",
    "\n",
    "final_mask=ignore_mask* iou.max() != iou\n",
    "noobj_box=box[final_mask,:]\n",
    "\n",
    "\n",
    "\n",
    "abs_pred_box=pred[0,iou_mask,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17*17*3+34*34*3+68*68*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou_mask[18207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= ((iou_mask == True).nonzero())\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.zeros([80])\n",
    "ar2=np.array([122,25,91,46,0.2])\n",
    "ar3=np.array([12,245,16,60,0.1])\n",
    "ar4=np.array([150,45,7,98,0.8])\n",
    "ar5=np.array([22,23,70,403,0.1])\n",
    "\n",
    "\n",
    "ar2=np.concatenate((ar2,array),axis=0)\n",
    "ar3=np.concatenate((ar3,array),axis=0)\n",
    "ar4=np.concatenate((ar4,array),axis=0)\n",
    "ar5=np.concatenate((ar5,array),axis=0)\n",
    "\n",
    "targets=torch.tensor([[ar2,ar3,ar4,ar5]])\n",
    "print(targets.shape)\n",
    "\n",
    "print(targets.shape)\n",
    "for obj in targets[0]:\n",
    "    print(obj.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=3\n",
    "batch=0\n",
    "obj=0\n",
    "target=torch.stack([targets[batch,obj,0:4] for a in range(anchors)])\n",
    "target=target.type(torch.float)\n",
    "target=util.get_abs_coord(target)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "    filename = str(cnt) + '.jpg'\n",
    "    row = []\n",
    "    parsedXML = ET.parse(file)\n",
    "    for node in parsedXML.getroot().iter('object'):\n",
    "        blood_cells = node.find('name').text\n",
    "        xmin = int(node.find('bndbox/xmin').text)\n",
    "        xmax = int(node.find('bndbox/xmax').text)\n",
    "        ymin = int(node.find('bndbox/ymin').text)\n",
    "        ymax = int(node.find('bndbox/ymax').text)\n",
    "        row = [prev_filename, filename, blood_cells, xmin, xmax,ymin, ymax]\n",
    "        df.append(row)\n",
    "    cnt += 1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type','xmin', 'xmax', 'ymin', 'ymax'])\n",
    "\n",
    "data[['filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0,2:]\n",
    "target[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "inp = get_test_input()\n",
    "\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "loss=util.yolo_loss(pred,targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    row=[]\n",
    "    parsedXML = ET.parse(file)\n",
    "    root= parsedXML.getroot()\n",
    "    if (cnt!=1):\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "    else:\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mpg'\n",
    "    for child in root[1][0]:\n",
    "        if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "            for obj in child[0]:\n",
    "                filename=file.split('/')[-1].split('.')[0]\n",
    "                obj_id=child.attrib['id']\n",
    "                framespan=obj.attrib['framespan']\n",
    "                x=int(obj.attrib['x'])\n",
    "                y=int(obj.attrib['y'])\n",
    "                width=int(obj.attrib['width'])\n",
    "                height=int(obj.attrib['height'])\n",
    "                row = [filename, obj_id, framespan, x, y,width, height]\n",
    "                df.append(row)\n",
    "    cnt=cnt+1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['filename', 'obj_id','framespan','x', 'y', 'width', 'height'])\n",
    "data.to_csv('annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import os, sys, random\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# from shutil import copyfile\n",
    "\n",
    "# annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "# cnt = 0\n",
    "# for file in annotations:\n",
    "#     row=[]\n",
    "#     parsedXML = ET.parse(file)\n",
    "#     root= parsedXML.getroot()\n",
    "#     file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "#     cap = cv2.VideoCapture('WOSDETC19/'+file)\n",
    "    \n",
    "#     file_jpg=file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "#     success = True\n",
    "#     while success:\n",
    "#         for child in root[1][0]:\n",
    "#             if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "#                 for obj in child[0]:\n",
    "#                     framespan=obj.attrib['framespan']\n",
    "#                     count = int(framespan.split(':')[0])\n",
    "#                     cap.set(cv2.CAP_PROP_POS_FRAMES, count-1)\n",
    "#                     success, frame = cap.read()\n",
    "#                     cv2.imwrite(\"images/\"+file_jpg+\"_img%d.jpg\" % count, frame)     # save frame as JPEG file      \n",
    "#         success=False\n",
    "#     cnt=cnt+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1024/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "df.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "from dataset import *\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph\n",
    "cx_cy=net.cx_cy\n",
    "stride=net.stride\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './batch_from_scratch.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "epochs=20\n",
    "\n",
    "\n",
    "lock=0\n",
    "total_loss=0\n",
    "batch_counter=0\n",
    "batch_loss=0\n",
    "\n",
    "\n",
    "anchors=torch.empty(pw_ph.shape).cuda()\n",
    "offset=torch.empty(cx_cy.shape).cuda()\n",
    "strd=torch.empty(stride.shape).cuda()\n",
    "\n",
    "transformed_dataset=DroneDatasetCSV(csv_file='../annotations.csv',\n",
    "                                           root_dir='../images/images/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ResizeToTensor(544)\n",
    "                                           ]))\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=2,\n",
    "                        shuffle=True, num_workers=1)\n",
    "\n",
    "print('loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample in enumerate(dataloader):\n",
    "    print(i_batch, sample['image'].size(),\n",
    "        sample['bbox_coord'].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_box=util.get_abs_coord(box[:,0:4])\n",
    "mask=get_mask(obj[0:2],13,416,3)\n",
    "\n",
    "print(absolute_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_box=torch.stack([obj[0:4] for a in range(3)])\n",
    "target_box=target_box.type(torch.float)\n",
    "target_box=get_abs_coord(target_box)\n",
    "\n",
    "iou=util.bbox_iou(target_box,absolute_box)\n",
    "\n",
    "iou_mask=iou.max() == iou\n",
    "box=box[iou_mask,:]\n",
    "iou_value=iou.max()\n",
    "print(iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(box[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(0.0240, grad_fn=<AddBackward0>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for x in pbar(range(10)):\n",
    "    x==x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    sys.stdout.write('\\rProgress is %d' %i)\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "batch=1\n",
    "\n",
    "epochs=20\n",
    "start = timeit.default_timer()\n",
    "\n",
    "lock=0\n",
    "remaining=0\n",
    "estimated=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    print(\"epoch \"+str(e))\n",
    "    for index, row in df.iterrows():\n",
    "        imgpath='../images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "        inp = get_test_input(imgpath)\n",
    "        targets=torch.tensor([[[row['x']*(416/1980),row['y']*(416/1080),row['width']*(416/1980),row['height']*(416/1080),1,1]]])\n",
    "        pred = model(inp, torch.cuda.is_available())\n",
    "        loss=util.yolo_loss(pred,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\rProgress is ' +str(prg_counter/8771*100)+'%' ' loss is: '+ str(loss.item())+' Time remaining is ' +str(estimated/60)+' min')\n",
    "        sys.stdout.flush()\n",
    "        prg_counter=prg_counter+1\n",
    "        if ((prg_counter/8771*100>1)&(lock==0)):\n",
    "            stop = timeit.default_timer()\n",
    "            estimated= (stop-start)*99\n",
    "            dur=stop-start\n",
    "            start=stop\n",
    "            lock=1\n",
    "        if estimated!=0:\n",
    "            stop = timeit.default_timer()\n",
    "            dur=stop-start\n",
    "            start=stop\n",
    "            estimated=estimated-dur\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "for x in range(100000000):\n",
    "    x=x+x\n",
    "time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../test_annotations.csv')\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './darknet.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluation_df = pd.DataFrame(columns=['pred_x', 'pred_y', 'pred_w','pred_h','pred_conf','pred_class','true_x','true_y','true_w','true_h','true_conf','true_class'])\n",
    "epochs=1\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['obj_id']==0)&(row['filename']+'_'+str(row['obj_id'])+'_img'+row['framespan'].split(':')[0]+'.jpg'!='gopro_001_0_img480.jpg'):\n",
    "            imgpath='../test_images/'+row['filename']+'_'+str(row['obj_id'])+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "            inp = get_test_input(imgpath)\n",
    "            targets=torch.tensor([[[row['x']*(416/1920),row['y']*(416/1080),row['width']*(416/1920),row['height']*(416/1080),1,1]]])\n",
    "            targets=targets.to(device='cuda')\n",
    "            pred = model(inp, torch.cuda.is_available())\n",
    "            pred=pred.to(device='cuda')\n",
    "            pred_mask=pred[0,:,4].max() == pred[0,:,4]\n",
    "            pred_final=pred[:,pred_mask]\n",
    "            pred_final=pred_final[0]\n",
    "            \n",
    "            abs_gt=util.get_abs_target_coord(targets[0])\n",
    "            abs_pred=util.get_abs_pred_coord(pred_final)\n",
    "            if util.bbox_iou(abs_gt, abs_pred).item()>0:\n",
    "                print(util.bbox_iou(abs_gt, abs_pred).item())\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "from dataset import *\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './new.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "transformed_dataset=DroneDatasetCSV(csv_file='../annotations.csv',\n",
    "                                           root_dir='../images/images/',\n",
    "                                           drone_size='large',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001,weight_decay=0.001)\n",
    "epochs=100\n",
    "total_loss=0\n",
    "write=0\n",
    "misses=0\n",
    "break_flag=0\n",
    "avg_iou=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    train_counter=0\n",
    "    total_loss=0\n",
    "    avg_iou=0\n",
    "    avg_infs=0\n",
    "    print(\"\\n epoch \"+str(e))\n",
    "    misses=0\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        write=0\n",
    "        sample_batched['image'],sample_batched['bbox_coord']=sample_batched['image'].to(device='cuda'),sample_batched['bbox_coord'].to(device='cuda')\n",
    "        raw_pred = model(sample_batched['image'], torch.cuda.is_available())\n",
    "        \n",
    "        target=util.xyxy_to_xywh(sample_batched['bbox_coord'].unsqueeze(-3))\n",
    "        \n",
    "        target=target.to(device='cuda')\n",
    "        raw_pred=raw_pred.to(device='cuda')\n",
    "        \n",
    "        for b in range(sample_batched['image'].shape[0]):\n",
    "            if (write==0):\n",
    "                anchors=pw_ph\n",
    "                offset=cx_cy\n",
    "                strd=stride\n",
    "                write=1\n",
    "            else:\n",
    "                anchors=torch.cat((anchors,pw_ph),0).to(device='cuda')\n",
    "                offset=torch.cat((offset,cx_cy),0).to(device='cuda')\n",
    "                strd=torch.cat((strd,stride),0).to(device='cuda')\n",
    "        \n",
    "        true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "        \n",
    "        iou_mask,noobj_mask=util.get_responsible_masks(true_pred,target)\n",
    "        \n",
    "        \n",
    "        abs_pred=util.get_abs_coord(true_pred)\n",
    "        abs_true=util.get_abs_coord(target)\n",
    "        \n",
    "        iou=util.bbox_iou(abs_pred,abs_true)\n",
    "        infs=iou.ne(iou).sum().item()\n",
    "        iou[iou.ne(iou)] = 0 #removes nan values\n",
    "        \n",
    "\n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        noobj_box=noobj_box[noobj_mask.T,:]\n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        \n",
    "        if(strd.shape[0]==sample_batched['image'].shape[0]):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            target=target.squeeze(-2)\n",
    "            target=target/strd\n",
    "            target=util.transform_groundtruth(target,anchors,offset)\n",
    "\n",
    "            loss=util.yolo_loss(raw_pred,target,noobj_box,batch_size)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss=total_loss+loss.item()\n",
    "            sys.stdout.write('\\r Progress is ' +str(prg_counter/dataset_len*100*batch_size)+'%' ' loss is: '+ str(loss.item()))\n",
    "            sys.stdout.write(' IoU is: ' + str(iou.max(dim=0)[0].mean().item())+' infs are: '+str(infs))\n",
    "            sys.stdout.flush()\n",
    "            del loss, raw_pred, target, true_pred\n",
    "            avg_iou=avg_iou+iou.max(dim=0)[0].mean().data#use .data in =+ statements \n",
    "            avg_infs=avg_infs+infs\n",
    "            torch.cuda.empty_cache()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            misses=misses+1\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))\n",
    "    print('\\n total average infs is '+str(avg_infs/train_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou.shape)\n",
    "print(sample_batched['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage import data, io\n",
    "from matplotlib import pyplot as plt\n",
    "index=5\n",
    "img=(sample_batched['image'][index])\n",
    "\n",
    "npimag=np.array(img.cpu())\n",
    "bbox=sample_batched['bbox_coord']\n",
    "print(bbox[index])\n",
    "print(iou.max(dim=0)[0][index])\n",
    "io.imshow(npimag[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in util.bbox_iou(abs_pred,abs_true)[:,5]:\n",
    "    if torch.isnan(n):\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(util.bbox_iou(abs_pred,abs_true)[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=abs_pred[:,5].unsqueeze(-3)\n",
    "b=abs_true[:,5].unsqueeze(-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1=a[mask,:]\n",
    "print(box1)\n",
    "box2=b\n",
    "#Get the coordinates of bounding boxes\n",
    "b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,:,0], box1[:,:,1], box1[:,:,2], box1[:,:,3]\n",
    "b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,:,0], box2[:,:,1], box2[:,:,2], box2[:,:,3]\n",
    "\n",
    "#get the coordinates of the intersection rectangle\n",
    "inter_rect_x1 =  torch.max(b1_x1, b2_x1)\n",
    "inter_rect_y1 =  torch.max(b1_y1, b2_y1)\n",
    "inter_rect_x2 =  torch.min(b1_x2, b2_x2)\n",
    "inter_rect_y2 =  torch.min(b1_y2, b2_y2)\n",
    "\n",
    "#Intersection area\n",
    "if torch.cuda.is_available():\n",
    "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 ,torch.zeros(inter_rect_x2.shape).cuda())*torch.max(inter_rect_y2 - inter_rect_y1 , torch.zeros(inter_rect_x2.shape).cuda())\n",
    "else:\n",
    "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 ,torch.zeros(inter_rect_x2.shape))*torch.max(inter_rect_y2 - inter_rect_y1 , torch.zeros(inter_rect_x2.shape))\n",
    "\n",
    "#Union Area\n",
    "b1_area = (b1_x2 - b1_x1 )*(b1_y2 - b1_y1 )\n",
    "b2_area = (b2_x2 - b2_x1 )*(b2_y2 - b2_y1 )\n",
    "\n",
    "iou = inter_area / (b1_area + b2_area - inter_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.isnan(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou[iou.ne(iou)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=true_pred[5][mask.squeeze(-2),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred = model(sample_batched['image'], torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('../annotations.csv')\n",
    "print(len(df))\n",
    "big=df['width']*df['height']>=1000\n",
    "\n",
    "medium=(df['width']*df['height']>=100)&(df['width']*df['height']<1000)\n",
    "small=100>df['width']*df['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_drones=df[big]\n",
    "medium_drones=df[medium]\n",
    "small_drones=df[small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(big_drones))\n",
    "print(len(medium_drones))\n",
    "print(len(small_drones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred = model(sample_batched['image'], torch.cuda.is_available())\n",
    "print(sample_batched['bbox_coord'])\n",
    "target=util.xyxy_to_xywh(sample_batched['bbox_coord'].unsqueeze(-3))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "abs_pred_coord=get_abs_coord(true_pred)\n",
    "abs_target_coord=get_abs_coord(target)\n",
    "print(abs_target_coord)\n",
    "print(abs_pred_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou=bbox_iou(abs_pred_coord,abs_target_coord)\n",
    "print(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from skimage import io, transform\n",
    "with tarfile.open(\"../sort_aug.tar.gz\", \"r\") as tar:\n",
    "    print(get_next(tar))\n",
    "    print(get_next(tar))\n",
    "    print(get_next(tar))\n",
    "#     img=tar.extract('home/konsa15/workspace/notebooks/drone_vs_bird/aug_images/00_10_09_to_00_10_40_img760_b8_a6.jpg')\n",
    "#     image = io.imread(img)\n",
    "#     print(image.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "class TarDataset():\n",
    "    def __init__(self):\n",
    "        self.tar= tarfile.open(\"../sort_aug.tar.gz\", \"r\")\n",
    "        self.tar.next()\n",
    "    \n",
    "            \n",
    "    def get_next(self):\n",
    "\n",
    "        return self.tar.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../augmented_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['filename'])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from skimage import io, transform\n",
    "\n",
    "import tarfile\n",
    "from augmDataset import *\n",
    "from skimage import io, transform\n",
    "\n",
    "transformed_dataset=AugDatasetCSV(csv_file='../augmented_data.csv',\n",
    "                                           archieve='../sort_aug.tar.gz',\n",
    "                                           root_dir='/aug_images/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ResizeToTensor(544)\n",
    "                                           ]))\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=16,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tar.getnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "from dataset import *\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './test.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "    \n",
    "drone_size='large+medium'\n",
    "print('training for '+ drone_size+'\\n')\n",
    "transformed_dataset=DroneDatasetCSV(csv_file='../annotations.csv',\n",
    "                                           root_dir='../images/images/',\n",
    "                                           drone_size=drone_size,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.005)\n",
    "epochs=150\n",
    "total_loss=0\n",
    "write=0\n",
    "misses=0\n",
    "break_flag=0\n",
    "avg_iou=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    train_counter=0\n",
    "    total_loss=0\n",
    "    avg_iou=0\n",
    "    avg_infs=0\n",
    "    print(\"\\n epoch \"+str(e))\n",
    "    misses=0\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        \n",
    "        write=0\n",
    "        optimizer.zero_grad()\n",
    "        sample_batched['image'],sample_batched['bbox_coord']=sample_batched['image'].to(device='cuda'),sample_batched['bbox_coord'].to(device='cuda')\n",
    "        raw_pred = model(sample_batched['image'], torch.cuda.is_available())\n",
    "        \n",
    "        target=sample_batched['bbox_coord'].unsqueeze(-3)\n",
    "        target=target.to(device='cuda')\n",
    "        raw_pred=raw_pred.to(device='cuda')\n",
    "        for b in range(sample_batched['image'].shape[0]):\n",
    "            if (write==0):\n",
    "                anchors=pw_ph\n",
    "                offset=cx_cy\n",
    "                strd=stride\n",
    "                write=1\n",
    "            else:\n",
    "                anchors=torch.cat((anchors,pw_ph),0).to(device='cuda')\n",
    "                offset=torch.cat((offset,cx_cy),0).to(device='cuda')\n",
    "                strd=torch.cat((strd,stride),0).to(device='cuda')\n",
    "                \n",
    "        true_pred=util.transform(raw_pred.clone(),anchors,offset,strd)\n",
    "        iou_mask,noobj_mask=util.get_responsible_masks(true_pred,target,offset,stride)\n",
    "        \n",
    "        \n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        noobj_box=noobj_box[noobj_mask.T,:]\n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        \n",
    "        conf=raw_pred[:,4].mean()\n",
    "        no_conf=noobj_box.mean()\n",
    "        \n",
    "        if(strd.shape[0]==sample_batched['image'].shape[0]):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            target=util.xyxy_to_xywh(target)\n",
    "            target=target.squeeze(1)\n",
    "            target=util.transform_groundtruth(target,anchors,offset,strd)\n",
    "            loss=util.yolo_loss(raw_pred,target,noobj_box,batch_size)\n",
    "            if (torch.isinf(loss)):\n",
    "                break_flag=1\n",
    "                break\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss=total_loss+loss.item()\n",
    "\n",
    "            sys.stdout.write('\\r Progress is ' +str(prg_counter/dataset_len*100*batch_size)+'%' ' loss is: '+ str(loss.item()))\n",
    "            sys.stdout.flush()\n",
    "#             del loss, raw_pred, target, true_pred, sample_batched['image']\n",
    "            torch.cuda.empty_cache()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            misses=misses+1\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "    if break_flag==1:\n",
    "        break\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))\n",
    "    print('\\n total average infs is '+str(avg_infs/train_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noobj_box==noobj_box.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor(inf, device='cuda:0')\n",
    "\n",
    "print(y==float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=model(sample_batched['image'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.shape)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=util.transform(raw.clone(),pw_ph,cx_cy,stride)\n",
    "print(true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first compute the centered target coords\n",
    "transformed_output=raw.clone()\n",
    "centered_target=util.xyxy_to_xywh(target)[:,:,0:2]\n",
    "#then devide by stride to get the relative grid size coordinates, floor the result to get the corresponding cell\n",
    "centered_target=torch.floor(centered_target/stride)\n",
    "\n",
    "#create a mask to find where the gt falls into which gridcell in the grid coordinate system\n",
    "fall_into_mask=centered_target==cx_cy\n",
    "fall_into_mask=fall_into_mask[:,:,0]&fall_into_mask[:,:,1]\n",
    "#     fall_into_mask= ~fall_into_mask\n",
    "#create a copy of the transformed output\n",
    "best_bboxes=transformed_output.clone()\n",
    "#apply reverse mask to copy in order to zero all other bbox locations\n",
    "best_bboxes[~fall_into_mask]=0   \n",
    "#transform the copy to xmin,xmax,ymin,ymax\n",
    "best_responsible_coord=util.get_abs_coord(best_bboxes)\n",
    "#calculate best iou and mask\n",
    "responsible_iou=util.bbox_iou(best_responsible_coord,target,True)\n",
    "\n",
    "responsible_iou[responsible_iou.ne(responsible_iou)] = 0\n",
    "responsible_mask=responsible_iou.max(dim=0)[0] == responsible_iou\n",
    "\n",
    "abs_coord=util.get_abs_coord(transformed_output)\n",
    "iou=util.bbox_iou(abs_coord,target,True)\n",
    "iou[iou.ne(iou)] = 0\n",
    "ignore_mask=0.5>iou\n",
    "inverted_mask=iou.max(dim=0)[0] != iou\n",
    "noobj_mask=ignore_mask & inverted_mask & ~responsible_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_mask,noobj_mask=util.get_responsible_masks(true,target,cx_cy,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noobj_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobj_box=raw[:,:,4:5].clone()\n",
    "noobj_box=noobj_box[noobj_mask.T,:]\n",
    "raw=raw[iou_mask.T,:]\n",
    "pw_ph=pw_ph[iou_mask.T,:]\n",
    "cx_cy=cx_cy[iou_mask.T,:]\n",
    "stride=stride[iou_mask.T,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target=util.xyxy_to_xywh(target)\n",
    "target=target.squeeze(1)\n",
    "\n",
    "target2=target/stride\n",
    "target2[:,0:2]=target2[:,0:2]-cx_cy\n",
    "# target[:,0:2]=torch.log(target[:,0:2]/(1-target[:,0:2]))\n",
    "# target[:,2:4]=torch.log(target[:,2:4]/pw_ph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Using  2 GPUs!\n",
      "training for all\n",
      "\n",
      "Length of dataset is 8771\n",
      "\n",
      "\n",
      " epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress is 12.495724546801961% loss is: 0.23145616054534912 Iou is 0.9071975946426392 conf is 0.9567434191703796 no_obj conf is 0.0033668631222099066"
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "from dataset import *\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = './test.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "def my_collate(batch):\n",
    "    write=0\n",
    "    boxes=[]\n",
    "    for el in batch:\n",
    "        if write==0:\n",
    "            pictures=el['image'].unsqueeze(-4)\n",
    "            write=1\n",
    "        else:\n",
    "            pictures=torch.cat((pictures,el['image'].unsqueeze(-4)),0)\n",
    "        boxes.append(el['bbox_coord'])\n",
    "\n",
    "    return pictures,boxes\n",
    "\n",
    "def collapse_boxes(boxes,pw_ph,cx_cy,stride):\n",
    "    write=0\n",
    "    mask=[]\n",
    "    for box in boxes:\n",
    "        if write==0:\n",
    "            targets=box\n",
    "            anchors=torch.stack([pw_ph for p in range(box.shape[0])], dim=0)\n",
    "            offset=torch.stack([cx_cy for p in range(box.shape[0])], dim=0)\n",
    "            strd=torch.stack([stride for p in range(box.shape[0])], dim=0)\n",
    "            write=1\n",
    "        else:\n",
    "            targets=torch.cat((targets,box),0)\n",
    "            \n",
    "            anchors=torch.cat((anchors,torch.stack([pw_ph for p in range(box.shape[0])], dim=0)),0)\n",
    "            offset=torch.cat((offset,torch.stack([cx_cy for p in range(box.shape[0])], dim=0)),0)\n",
    "            strd=torch.cat((strd,torch.stack([stride for p in range(box.shape[0])], dim=0)),0)\n",
    "        mask.append(box.shape[0])\n",
    "    return targets,anchors.squeeze(1),offset.squeeze(1),strd.squeeze(1),mask\n",
    "\n",
    "def expand_predictions(predictions,mask):\n",
    "    k=0\n",
    "    write=0\n",
    "    for i in mask:\n",
    "        if write==0:\n",
    "            new=torch.stack([predictions[k,:,:] for p in range(i)], dim=0)\n",
    "            write=1\n",
    "        else:\n",
    "            new=torch.cat((new,torch.stack([predictions[k,:,:] for p in range(i)], dim=0)),0)\n",
    "        k=k+1\n",
    "    \n",
    "    return new\n",
    "            \n",
    "    \n",
    "\n",
    "drone_size='all'\n",
    "print('training for '+ drone_size+'\\n')\n",
    "transformed_dataset=DroneDatasetCSV(csv_file='../annotations.csv',\n",
    "                                           root_dir='../images/images/',\n",
    "                                           drone_size=drone_size,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "    \n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=my_collate, num_workers=0)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.005)\n",
    "epochs=150\n",
    "total_loss=0\n",
    "write=0\n",
    "misses=0\n",
    "break_flag=0\n",
    "avg_iou=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    train_counter=0\n",
    "    total_loss=0\n",
    "    avg_iou=0\n",
    "    avg_infs=0\n",
    "    print(\"\\n epoch \"+str(e))\n",
    "    misses=0\n",
    "    for images,targets in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        targets,anchors,offset,strd,mask=collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "        raw_pred = model(images, torch.cuda.is_available())\n",
    "        raw_pred=expand_predictions(raw_pred,mask)\n",
    "        true_pred=util.transform(raw_pred.clone(),anchors,offset,strd)\n",
    "        targets=targets.unsqueeze(-3).cuda()\n",
    "        iou_mask,noobj_mask=util.get_responsible_masks(true_pred,targets,offset,strd,mask)\n",
    "        \n",
    "        iou=torch.diag(util.bbox_iou(util.get_abs_coord(true_pred[iou_mask.T,:].unsqueeze(-3)),targets)).mean().item()\n",
    "        \n",
    "        \n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        conf=noobj_box[iou_mask.T,:].mean().item()\n",
    "        \n",
    "        noobj_box=noobj_box[noobj_mask.T,:]\n",
    "        no_obj_conf=noobj_box.mean().item()\n",
    "        \n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        \n",
    "        if(strd.shape[0]==sum(mask)):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            targets=util.xyxy_to_xywh(targets)\n",
    "            targets=targets.squeeze(1)\n",
    "            targets=util.transform_groundtruth(targets,anchors,offset,strd)\n",
    "            loss=util.yolo_loss(raw_pred,targets,noobj_box,batch_size)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss=total_loss+loss.item()\n",
    "            avg_iou=avg_iou+iou\n",
    "            sys.stdout.write('\\r Progress is ' +str(prg_counter/dataset_len*100*batch_size)+'%' ' loss is: '+ str(loss.item()))\n",
    "            sys.stdout.write(' Iou is ' +str(iou)+' conf is '+str(conf)+ ' no_obj conf is '+str(no_obj_conf))\n",
    "            sys.stdout.flush()\n",
    "            del loss, raw_pred, targets, true_pred, images,iou,noobj_box,conf\n",
    "            torch.cuda.empty_cache()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            misses=misses+1\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False+torch.tensor([True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 39375, 6])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
