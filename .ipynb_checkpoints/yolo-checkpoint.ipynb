{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "model.load_weights(\"yolov3.weights\")\n",
    "inp = get_test_input()\n",
    "blocks = parse_cfg(\"cfg/yolov3.cfg\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(inp, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 85])\n",
      "torch.Size([1, 4, 85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n",
      "torch.Size([85])\n"
     ]
    }
   ],
   "source": [
    "array=np.zeros([80])\n",
    "ar2=np.array([122,25,91,46,0.2])\n",
    "ar3=np.array([12,245,16,60,0.1])\n",
    "ar4=np.array([150,45,7,98,0.8])\n",
    "ar5=np.array([22,23,70,403,0.1])\n",
    "\n",
    "\n",
    "ar2=np.concatenate((ar2,array),axis=0)\n",
    "ar3=np.concatenate((ar3,array),axis=0)\n",
    "ar4=np.concatenate((ar4,array),axis=0)\n",
    "ar5=np.concatenate((ar5,array),axis=0)\n",
    "\n",
    "targets=torch.tensor([[ar2,ar3,ar4,ar5]])\n",
    "print(targets.shape)\n",
    "\n",
    "print(targets.shape)\n",
    "for obj in targets[0]:\n",
    "    print(obj.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=3\n",
    "batch=0\n",
    "obj=0\n",
    "target=torch.stack([targets[batch,obj,0:4] for a in range(anchors)])\n",
    "target=target.type(torch.float)\n",
    "target=util.get_abs_coord(target)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    prev_filename = file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "    filename = str(cnt) + '.jpg'\n",
    "    row = []\n",
    "    parsedXML = ET.parse(file)\n",
    "    for node in parsedXML.getroot().iter('object'):\n",
    "        blood_cells = node.find('name').text\n",
    "        xmin = int(node.find('bndbox/xmin').text)\n",
    "        xmax = int(node.find('bndbox/xmax').text)\n",
    "        ymin = int(node.find('bndbox/ymin').text)\n",
    "        ymax = int(node.find('bndbox/ymax').text)\n",
    "        row = [prev_filename, filename, blood_cells, xmin, xmax,ymin, ymax]\n",
    "        df.append(row)\n",
    "    cnt += 1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type','xmin', 'xmax', 'ymin', 'ymax'])\n",
    "\n",
    "data[['filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0,2:]\n",
    "target[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "inp = get_test_input()\n",
    "\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "loss=util.yolo_loss(pred,targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "\n",
    "df = []\n",
    "cnt = 0\n",
    "for file in annotations:\n",
    "    row=[]\n",
    "    parsedXML = ET.parse(file)\n",
    "    root= parsedXML.getroot()\n",
    "    if (cnt!=1):\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "    else:\n",
    "        file=file.split('/')[-1].split('.')[0] + '.mpg'\n",
    "    for child in root[1][0]:\n",
    "        if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "            for obj in child[0]:\n",
    "                filename=file.split('/')[-1].split('.')[0]\n",
    "                obj_id=child.attrib['id']\n",
    "                framespan=obj.attrib['framespan']\n",
    "                x=int(obj.attrib['x'])\n",
    "                y=int(obj.attrib['y'])\n",
    "                width=int(obj.attrib['width'])\n",
    "                height=int(obj.attrib['height'])\n",
    "                row = [filename, obj_id, framespan, x, y,width, height]\n",
    "                df.append(row)\n",
    "    cnt=cnt+1\n",
    "\n",
    "data = pd.DataFrame(df, columns=['filename', 'obj_id','framespan','x', 'y', 'width', 'height'])\n",
    "data.to_csv('annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import os, sys, random\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# from shutil import copyfile\n",
    "\n",
    "# annotations = sorted(glob('WOSDETC19/*.xml'))\n",
    "# cnt = 0\n",
    "# for file in annotations:\n",
    "#     row=[]\n",
    "#     parsedXML = ET.parse(file)\n",
    "#     root= parsedXML.getroot()\n",
    "#     file=file.split('/')[-1].split('.')[0] + '.mp4'\n",
    "#     cap = cv2.VideoCapture('WOSDETC19/'+file)\n",
    "    \n",
    "#     file_jpg=file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "#     success = True\n",
    "#     while success:\n",
    "#         for child in root[1][0]:\n",
    "#             if(child.tag=='{http://lamp.cfar.umd.edu/viper#}object'):\n",
    "#                 for obj in child[0]:\n",
    "#                     framespan=obj.attrib['framespan']\n",
    "#                     count = int(framespan.split(':')[0])\n",
    "#                     cap.set(cv2.CAP_PROP_POS_FRAMES, count-1)\n",
    "#                     success, frame = cap.read()\n",
    "#                     cv2.imwrite(\"images/\"+file_jpg+\"_img%d.jpg\" % count, frame)     # save frame as JPEG file      \n",
    "#         success=False\n",
    "#     cnt=cnt+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../annotations.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) ../modules/imgproc/src/resize.cpp:3718: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f72dda0a81ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mimgpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_img'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'framespan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/notebooks/drone_vs_bird/yolo_v3_drn_vs_brd/darknet.py\u001b[0m in \u001b[0;36mget_test_input\u001b[0;34m(imgpath)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#Resize to the input dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mimg_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BGR -> RGB | H X W C -> C X H X W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m       \u001b[0;31m#Add a channel at 0 (for batch) | Normalise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) ../modules/imgproc/src/resize.cpp:3718: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Darknet(\"../cfg/yolov3.cfg\")\n",
    "model.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "batch=1\n",
    "k=0\n",
    "cost=0\n",
    "for index, row in df.iterrows():\n",
    "#     imgpath='../images/'+row['filename']+'_img'+row['framespan'].split(':')[0]+'.jpg'\n",
    "#     inp = get_test_input(imgpath)\n",
    "#     targets=torch.tensor([[[row['x']*(416/1980),row['y']*(416/1080),row['width']*(416/1980),row['height']*(416/1080),1,1]]])\n",
    "#     pred = model(inp, torch.cuda.is_available())\n",
    "#     loss=util.yolo_loss(pred,targets)\n",
    "#     print(loss)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "    index=1\n",
    "    imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "    inp = get_test_input(imgpath)\n",
    "    targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "    pred = model(inp, torch.cuda.is_available())\n",
    "    loss=util.yolo_loss(pred,targets)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#     cost=cost+loss\n",
    "#     if(k==batch):\n",
    "#         print(cost)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "#         cost=0\n",
    "#         k=0\n",
    "#     k=k+1\n",
    "    \n",
    "\n",
    "   \n",
    "index=10\n",
    "imgpath='../images/'+df['filename'][index]+'_img'+df['framespan'][index].split(':')[0]+'.jpg'\n",
    "inp = get_test_input(imgpath)\n",
    "targets=torch.tensor([[[df['x'][index]*(416/1980),df['y'][index]*(416/1080),df['width'][index]*(416/1980),df['height'][index]*(416/1080),1,1]]])\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "print(pred)\n",
    "loss=util.yolo_loss(pred,targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=torch.tensor([123.5394, 284.6519,   5.2525,   6.9333,   1.0000,   1.0000])\n",
    "box=torch.tensor([[9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02],\n",
    "        [9.6394e+01, 2.5649e+02, 1.3267e+00, 3.3532e-01, 2.0614e-03, 8.3126e-03],\n",
    "        [9.6071e+01, 2.5609e+02, 1.1885e+00, 4.8042e-01, 2.5095e-03, 2.6043e-03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 72.4265, 236.5345, 117.5735, 292.7255],\n",
      "        [ 94.7306, 255.3223,  96.0574, 255.6577],\n",
      "        [ 94.4767, 254.8498,  95.6653, 255.3302]])\n"
     ]
    }
   ],
   "source": [
    "absolute_box=util.get_abs_coord(box[:,0:4])\n",
    "mask=get_mask(obj[0:2],13,416,3)\n",
    "\n",
    "print(absolute_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target_box=torch.stack([obj[0:4] for a in range(3)])\n",
    "target_box=target_box.type(torch.float)\n",
    "target_box=get_abs_coord(target_box)\n",
    "\n",
    "iou=util.bbox_iou(target_box,absolute_box)\n",
    "\n",
    "iou_mask=iou.max() == iou\n",
    "box=box[iou_mask,:]\n",
    "iou_value=iou.max()\n",
    "print(iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.6000e+01, 2.6563e+02, 4.5147e+01, 5.6191e+01, 2.7485e-04, 1.0556e-02])\n"
     ]
    }
   ],
   "source": [
    "print(box[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor(0.0240, grad_fn=<AddBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
